{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "EbqlwB8PSqO5"
   },
   "outputs": [],
   "source": [
    "!pip install torch==0.4.0\n",
    "!pip install torchvision\n",
    "!pip install progressbar2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fpg8k07oVCWk"
   },
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "cRDMRi-0TFZZ"
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import progressbar\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision.utils as vutils\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VpL5Jmk5WR0V"
   },
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "msImkaoJSqPB"
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = './data/CIFAR-10'\n",
    "BATCH_SIZE = 100\n",
    "LR = 0.0002\n",
    "NUM_EPOCHS = 200\n",
    "NUM_TEST_SAMPLES = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mQjEltAkSqPH"
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "hfx_5qtCSqPJ",
    "outputId": "9cbf6dc1-8fb1-4a48-f923-6c2860cf8b09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "No. of Batches =  500\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    compose = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(64),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "        ])\n",
    "    return datasets.CIFAR10(root=OUTPUT_DIR, train=True, transform=compose, download=True)\n",
    "  \n",
    "data = load_data()\n",
    "# data = torch.utils.data.Subset(data, [0, 5000])\n",
    "data_loader = torch.utils.data.DataLoader(data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "NUM_BATCHES = len(data_loader)\n",
    "\n",
    "print(\"No. of Batches = \", NUM_BATCHES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aRj9MV1DSqPV"
   },
   "source": [
    "# Building GAN\n",
    "\n",
    "This section builds a Generative Adversarial Network (GAN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5rT8lkr9ZOyc"
   },
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "cNpeIZYeSqPW"
   },
   "outputs": [],
   "source": [
    "class Discriminator(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels=3, out_channels=128, kernel_size=4, stride=2, padding=1, bias=False), nn.LeakyReLU(0.2, inplace=True))\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1, bias=False), nn.BatchNorm2d(256), nn.LeakyReLU(0.2, inplace=True))\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=2, padding=1, bias=False), nn.BatchNorm2d(512), nn.LeakyReLU(0.2, inplace=True))\n",
    "        self.conv4 = nn.Sequential(nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=4, stride=2, padding=1, bias=False), nn.BatchNorm2d(1024), nn.LeakyReLU(0.2, inplace=True))\n",
    "        self.output = nn.Sequential(nn.Linear(1024*4*4, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        # Flatten and apply sigmoid\n",
    "        x = x.view(-1, 1024*4*4)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mCAzw6YSdCOU"
   },
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "1QBNfol4SqPb"
   },
   "outputs": [],
   "source": [
    "class Generator(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.linear = torch.nn.Linear(100, 1024*4*4)\n",
    "        self.deconv1 = nn.Sequential(nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=4, stride=2, padding=1, bias=False), nn.BatchNorm2d(512), nn.ReLU(inplace=True))\n",
    "        self.deconv2 = nn.Sequential(nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=4, stride=2, padding=1, bias=False), nn.BatchNorm2d(256), nn.ReLU(inplace=True))\n",
    "        self.deconv3 = nn.Sequential(nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=4, stride=2, padding=1, bias=False), nn.BatchNorm2d(128), nn.ReLU(inplace=True))\n",
    "        self.deconv4 = nn.Sequential(nn.ConvTranspose2d(in_channels=128, out_channels=3, kernel_size=4, stride=2, padding=1, bias=False))\n",
    "        self.output = torch.nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Project and reshape\n",
    "        x = self.linear(x)\n",
    "        x = x.view(x.shape[0], 1024, 4, 4)\n",
    "        \n",
    "        # Convolutional layers\n",
    "        x = self.deconv1(x)\n",
    "        x = self.deconv2(x)\n",
    "        x = self.deconv3(x)\n",
    "        x = self.deconv4(x)\n",
    "        \n",
    "        # Apply Tanh\n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xgiSOSZPc8Na"
   },
   "source": [
    "# Generating Artificial Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "wNCvK5llc45j"
   },
   "outputs": [],
   "source": [
    "def noise(size):\n",
    "    n = Variable(torch.randn(size, 100))\n",
    "    if torch.cuda.is_available(): \n",
    "      return n.cuda()\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Lq-9ipo2SqPh"
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1 or classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(0.00, 0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nuopfhNJfVR0"
   },
   "source": [
    "# Initializing Generator and Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "auVbeHbdSqPm"
   },
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "generator.apply(init_weights)\n",
    "discriminator.apply(init_weights)\n",
    "\n",
    "# Enable cuda if available\n",
    "if torch.cuda.is_available():\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sys_K3R_SqPt"
   },
   "source": [
    "# Optimization\n",
    "\n",
    "Defining optimizers for Generator and Discriminator nets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "aks2cpH3SqPx"
   },
   "outputs": [],
   "source": [
    "# d_optimizer = optim.SGD(discriminator.parameters(), lr=LR, momentum=0.9)\n",
    "# g_optimizer = optim.SGD(generator.parameters(), lr=LR, momentum=0.9)\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=LR, betas=(0.5, 0.999))\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=LR, betas=(0.5, 0.999))\n",
    "\n",
    "# Loss function\n",
    "# criterion = nn.MSELoss()\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "## Use Adam Optimizer with BCELoss function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3gLpa-17SqP4"
   },
   "source": [
    "# Setting Train Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "QJ-pD9pHSqP6"
   },
   "outputs": [],
   "source": [
    "def real_data_target(size):\n",
    "    data = Variable(torch.ones(size, 1))\n",
    "    if torch.cuda.is_available(): \n",
    "      return data.cuda()\n",
    "    return data\n",
    "\n",
    "def fake_data_target(size):\n",
    "    data = Variable(torch.zeros(size, 1))\n",
    "    if torch.cuda.is_available(): \n",
    "      return data.cuda()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "YjYFR3EFSqP_"
   },
   "outputs": [],
   "source": [
    "def train_discriminator(optimizer, real_data, fake_data):\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 1.1 Train on Real Data\n",
    "    prediction_real = discriminator(real_data)\n",
    "    # Calculate error and backpropagate\n",
    "    error_real = criterion(prediction_real, real_data_target(real_data.size(0)))\n",
    "    error_real.backward()\n",
    "\n",
    "    # 1.2 Train on Fake Data\n",
    "    prediction_fake = discriminator(fake_data)\n",
    "    # Calculate error and backpropagate\n",
    "    error_fake = criterion(prediction_fake, fake_data_target(real_data.size(0)))\n",
    "    error_fake.backward()\n",
    "    \n",
    "    # 1.3 Update weights with gradients\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Return error\n",
    "    return error_real + error_fake, prediction_real, prediction_fake\n",
    "\n",
    "def train_generator(optimizer, fake_data):\n",
    "    # 2. Train Generator\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    # Sample noise and generate fake data\n",
    "    prediction = discriminator(fake_data)\n",
    "    # Calculate error and backpropagate\n",
    "    error = criterion(prediction, real_data_target(prediction.size(0)))\n",
    "    error.backward()\n",
    "    # Update weights with gradients\n",
    "    optimizer.step()\n",
    "    # Return error\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CymMIVIrSqQE"
   },
   "source": [
    "# Generating Samples for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "o2ZTjqWoSqQG"
   },
   "outputs": [],
   "source": [
    "test_noise = noise(NUM_TEST_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y0K9wl_kokwq"
   },
   "source": [
    "# Generate Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "1H4waKE2SqQU"
   },
   "outputs": [],
   "source": [
    "def generate_images(test_images, num_images, normalize=True):\n",
    "  images = test_images\n",
    "  \n",
    "  # Make horizontal grid from image tensor\n",
    "  horizontal_grid = vutils.make_grid(images, normalize=normalize, scale_each=True)\n",
    "  # Make vertical grid from image tensor\n",
    "  nrows = int(np.sqrt(num_images))\n",
    "  grid = vutils.make_grid(images, nrow=nrows, normalize=True, scale_each=True)\n",
    "\n",
    "  # Plot and save horizontal\n",
    "  fig = plt.figure(figsize=(16, 16))\n",
    "  plt.imshow(np.moveaxis(horizontal_grid.numpy(), 0, -1))\n",
    "  plt.axis('off')\n",
    "  if True:\n",
    "    display.display(plt.gcf())\n",
    "  plt.close()\n",
    "\n",
    "  # Save squared\n",
    "  fig = plt.figure()\n",
    "  plt.imshow(np.moveaxis(grid.numpy(), 0, -1))\n",
    "  plt.axis('off')\n",
    "  plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RXWJuXVIpVCS"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "  print(\"\\nEpoch #\", epoch, \"in progress...\")\n",
    "  progress_bar = progressbar.ProgressBar()\n",
    "  d_running_loss = 0\n",
    "  g_running_loss = 0\n",
    "    \n",
    "  for n_batch, (real_batch, _) in enumerate(progress_bar(data_loader)):    \n",
    "    # 1. Train Discriminator\n",
    "#     inputs, _ = real_batch\n",
    "    real_data = Variable(real_batch)\n",
    "    if torch.cuda.is_available(): \n",
    "      real_data = real_data.cuda()\n",
    "    # Generate fake data\n",
    "    fake_data = generator(noise(real_data.size(0))).detach()\n",
    "    # Train D\n",
    "    d_error, d_pred_real, d_pred_fake = train_discriminator(d_optimizer, real_data, fake_data)\n",
    "\n",
    "    # 2. Train Generator\n",
    "    # Generate fake data\n",
    "    fake_data = generator(noise(real_batch.size(0)))\n",
    "    # Train G\n",
    "    g_error = train_generator(g_optimizer, fake_data)\n",
    "    \n",
    "    d_running_loss += d_error.data[0]\n",
    "    g_running_loss += g_error.data[0]\n",
    "  \n",
    "    \n",
    "#     loss = criterion(outputs, inputs)\n",
    "  print(\"Loss (Discriminator):\", d_running_loss)\n",
    "  print(\"Loss (Generator):\", g_running_loss)\n",
    "    \n",
    "  test_images = generator(test_noise).data.cpu()\n",
    "  generate_images(test_images, NUM_TEST_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sYasjd11PjBe"
   },
   "source": [
    "# Generating Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Rrr4PvtHsIqx"
   },
   "outputs": [],
   "source": [
    "num_samples = NUM_TEST_SAMPLES\n",
    "test_noise = noise(num_samples)\n",
    "test_images = generator(test_noise).data.cpu()\n",
    "generate_images(test_images, NUM_TEST_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EtLRioBy8Qia"
   },
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h4o4cqEo8Rb4"
   },
   "source": [
    "Report can be found at \"../report/main.pdf\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "generative-adversarial-network-model-3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
